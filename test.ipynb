{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 26, 26])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2e1b7ddfc0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.choices import *\n",
    "from model.utils import *\n",
    "eagle_choice = mc_sim_7b_63\n",
    "eagle_buffer = generate_tree_buffers(eagle_choice, device='cpu')\n",
    "eagle_attn_mask = eagle_buffer['tree_attn_mask']\n",
    "print(eagle_attn_mask.shape)\n",
    "\n",
    "plt.imshow(eagle_attn_mask[0,0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,  11,  12,  13,  21,  22,  31,  32,  41,  51,\n",
       "         52,  53,  61,  62,  71,  72,  81,  91,  92,  93, 101, 102])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagle_buffer['tree_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "        5, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagle_buffer['tree_position_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,  11,  12,  13,  21,  22,  31,  32,  41,  51,\n",
       "         52,  53,  61,  62,  71,  72,  81,  91,  92,  93, 101, 102])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagle_buffer['tree_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  5, 13, 21, 25],\n",
       "        [ 0,  1,  5, 13, 21, 24],\n",
       "        [ 0,  1,  5, 13, 23, -1],\n",
       "        [ 0,  1,  5, 13, 22, -1],\n",
       "        [ 0,  2,  8, 20, -1, -1],\n",
       "        [ 0,  1,  7, 19, -1, -1],\n",
       "        [ 0,  1,  7, 18, -1, -1],\n",
       "        [ 0,  1,  6, 17, -1, -1],\n",
       "        [ 0,  1,  6, 16, -1, -1],\n",
       "        [ 0,  1,  5, 15, -1, -1],\n",
       "        [ 0,  1,  5, 14, -1, -1],\n",
       "        [ 0,  4, 12, -1, -1, -1],\n",
       "        [ 0,  3, 11, -1, -1, -1],\n",
       "        [ 0,  3, 10, -1, -1, -1],\n",
       "        [ 0,  2,  9, -1, -1, -1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagle_buffer['retrieve_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2e1b74cc10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.choices import *\n",
    "from model.utils import *\n",
    "eagle_choice = chain_5\n",
    "eagle_buffer = generate_tree_buffers(eagle_choice, device='cpu')\n",
    "eagle_attn_mask = eagle_buffer['tree_attn_mask']\n",
    "\n",
    "print(eagle_attn_mask.shape)\n",
    "\n",
    "plt.imshow(eagle_attn_mask[0,0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1, 11, 21, 31, 41])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagle_buffer['tree_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_attn_mask': tensor([[[[1., 0., 0., 0., 0., 0.],\n",
       "           [1., 1., 0., 0., 0., 0.],\n",
       "           [1., 1., 1., 0., 0., 0.],\n",
       "           [1., 1., 1., 1., 0., 0.],\n",
       "           [1., 1., 1., 1., 1., 0.],\n",
       "           [1., 1., 1., 1., 1., 1.]]]]),\n",
       " 'tree_indices': tensor([ 0,  1, 11, 21, 31, 41]),\n",
       " 'tree_position_ids': tensor([0, 1, 2, 3, 4, 5]),\n",
       " 'retrieve_indices': tensor([[0, 1, 2, 3, 4, 5]])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagle_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jewon/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [01:06<00:00,  4.41s/it]\n",
      "/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from model.ea_model import EaModel\n",
    "import torch\n",
    "import time\n",
    "\n",
    "base_model_path = \"/ssd0/data/fast-llm/Llama-2-70B-Chat-fp16/\"\n",
    "EAGLE_model_path = \"yuhuili/EAGLE-llama2-chat-70B\"\n",
    "\n",
    "\n",
    "model = EaModel.from_pretrained(  \n",
    "    base_model_path=base_model_path,  \n",
    "    ea_model_path=EAGLE_model_path,  \n",
    "    torch_dtype=torch.float16,  \n",
    "    low_cpu_mem_usage=True,  \n",
    "    device_map=\"auto\"  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jewon/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [00:48<00:00,  3.21s/it]\n",
      "/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "prompt=\"Hello Nice to meet you! give me a five story about human and AI\"\n",
    "\n",
    "base_model_path = \"/ssd0/data/fast-llm/Llama-2-70B-Chat-fp16/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_path, \n",
    "                                             torch_dtype=torch.float16, \n",
    "                                             low_cpu_mem_usage=True, \n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 161]), torch.Size([3, 161]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_list = [prompt*10] * 3\n",
    "dummy = tokenizer.batch_encode_plus(dummy_list, return_tensors=\"pt\")\n",
    "dummy.input_ids.shape, dummy.attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_dummy = prompt*10\n",
    "single_dummy = tokenizer.encode_plus(single_dummy, return_tensors=\"pt\")\n",
    "single_dummy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38752853870391846\n",
      "0.23229742050170898\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "dummy.to(\"cuda\")\n",
    "single_dummy.to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "warmup = 10\n",
    "tot = 0\n",
    "\n",
    "for _ in range(warmup):\n",
    "    model(input_ids=dummy.input_ids,\n",
    "          attention_mask=dummy.attention_mask)\n",
    "\n",
    "for i in range(20):\n",
    "    tic = time.time()\n",
    "    model(input_ids=dummy.input_ids,\n",
    "          attention_mask=dummy.attention_mask)\n",
    "    toc =time.time()\n",
    "    tot += (toc-tic) \n",
    "    \n",
    "for i in range(1):\n",
    "    tic_single = time.time()\n",
    "    model(input_ids=single_dummy.input_ids,)\n",
    "    toc_single =time.time()\n",
    "    \n",
    "print(tot/20)\n",
    "print(toc_single-tic_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jewon/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (0.15.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from tokenizers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /home/jewon/.local/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jewon/.local/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jewon/.local/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/EAGLE/lib/python3.8/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def list_files(path):\n",
    "    datapath = []\n",
    "    for root, directories, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            datapath.append(file_path)\n",
    "    return datapath\n",
    "\n",
    "datapath=list_files(\"/ssd0/data/fast-llm/eagle_train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_config={\n",
    "    \"is_warmup\":True,\n",
    "    \"num_epochs\":10,\n",
    "    \"num_warmup_steps\":4000,\n",
    "    \"total_steps\":81490,\n",
    "    \"p_w\":0.1,\n",
    "    \"v_w\":1.0,\n",
    "    \"head_w\":0.1,\n",
    "    \"num_workers\":16,\n",
    "    \"embeding\":True,\n",
    "    \"act\":\"No\",\n",
    "    \"data_noise\":True,\n",
    "    \"noise\":\"uniform\",\n",
    "    \"mean\":0.0,\n",
    "    \"std\":0.2,\n",
    "    \"residual\":\"true,norm\",\n",
    "    \"max_len\":2048,\n",
    "    \"b1\":0.9,\n",
    "    \"b2\": 0.95,\n",
    "    \"grad_clip\": 0.5,\n",
    "}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datapath, transform=None):\n",
    "        self.data=datapath\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # try:\n",
    "        data=torch.load(self.data[index])\n",
    "        new_data={}\n",
    "        hidden_state=data['hidden_state'][:train_config[\"max_len\"]][None,:]\n",
    "        input_ids = data['input_ids'][:train_config[\"max_len\"]][None,:]\n",
    "        loss_mask = data[\"loss_mask\"][:train_config[\"max_len\"]][None,:]\n",
    "\n",
    "        # except:\n",
    "        #     with open(\"error_path.txt\", \"w\") as file:\n",
    "        #         file.write(self.data[index])\n",
    "        #     print('error path',self.data[index])\n",
    "\n",
    "\n",
    "        length=hidden_state.shape[1]\n",
    "        #length_q = data['query_ids'].shape[1]\n",
    "        attention_mask=[1]*length\n",
    "        loss_mask=loss_mask[0].tolist()\n",
    "        loss_mask[-1]=0\n",
    "\n",
    "        input_ids_target=input_ids[:,1:]\n",
    "        zeropadding = torch.tensor([[0]])\n",
    "        input_ids_target = torch.cat((input_ids_target, zeropadding), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        target=hidden_state[:,1:,:]\n",
    "        zeropadding=torch.zeros(1, 1, target.shape[2])\n",
    "        target=torch.cat((target,zeropadding), dim=1)\n",
    "        loss_mask[-1]=0\n",
    "        new_data[\"attention_mask\"] = attention_mask\n",
    "        new_data[\"loss_mask\"] = loss_mask\n",
    "        new_data[\"target\"]=target\n",
    "        new_data[\"hidden_state_big\"]=hidden_state\n",
    "        new_data[\"input_ids\"] = input_ids_target\n",
    "        #sample = torch.cat((data['xs'],data['xb']))\n",
    "        # sample=torch.cat((self.data[index]['x'],self.data[index]['logits']))\n",
    "        #label = data['y']\n",
    "\n",
    "        if self.transform:\n",
    "            new_data = self.transform(new_data)\n",
    "\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "\n",
    "\n",
    "    def paddingtensor(self,intensors,N):\n",
    "        B,n,S=intensors.shape\n",
    "        #padding_tensor = torch.zeros(B, N - n, S,dtype=intensors.dtype)\n",
    "        padding_tensor = torch.zeros(B, N - n, S)\n",
    "        outtensors = torch.cat((intensors, padding_tensor), dim=1)\n",
    "        return outtensors\n",
    "\n",
    "    def paddingtensor2D(self,intensors,N):\n",
    "        B,n=intensors.shape\n",
    "        padding_tensor = torch.zeros(B, N - n,dtype=intensors.dtype)\n",
    "        outtensors = torch.cat((intensors, padding_tensor), dim=1)\n",
    "        return outtensors\n",
    "\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        max_length = max(item['hidden_state_big'].shape[1] for item in features)\n",
    "        batch_input_ids = torch.cat([self.paddingtensor2D(item['input_ids'], max_length) for item in features])\n",
    "        batch_hidden_states=torch.cat([self.paddingtensor(item['hidden_state_big'],max_length) for item in features])\n",
    "        batch_target = torch.cat([self.paddingtensor(item['target'], max_length) for item in features])\n",
    "        batch_loss_mask = torch.tensor([item['loss_mask'] + [0] * (max_length - len(item['loss_mask'])) for item in features])\n",
    "        batch_attention_mask = torch.tensor([item['attention_mask'] + [0] * (max_length - len(item['attention_mask'])) for item in features])\n",
    "        # batch_loss_mask = torch.ones_like(batch_loss_mask)\n",
    "        # batch_attention_mask=torch.ones_like(batch_attention_mask)\n",
    "        batch = {\n",
    "            \"input_ids\":batch_input_ids,\n",
    "            \"hidden_states\": batch_hidden_states,\n",
    "            \"target\":batch_target,\n",
    "            \"attention_mask\": batch_attention_mask,\n",
    "            \"loss_mask\": batch_loss_mask,\n",
    "        }\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset=CustomDataset(datapath)\n",
    "train_loader=DataLoader(traindataset, batch_size=3, shuffle=True,collate_fn=DataCollatorWithPadding(),num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108641.99999999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*0.95*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4289"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186257.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*0.95 *20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "Hello?\n",
      "\n",
      "### Assistant:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 774, 1247, 28747, 13, 16230, 28804, 13, 13, 27332, 21631, 28747, 13]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Upstage/SOLAR-10.7B-Instruct-v1.0\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"Upstage/SOLAR-10.7B-Instruct-v1.0\",\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "conversation = [ {'role': 'user', 'content': 'Hello?'} ] \n",
    "\n",
    "prompt = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "print(prompt)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "# outputs = model.generate(**inputs, use_cache=True, max_length=4096)\n",
    "# output_text = tokenizer.decode(outputs[0]) \n",
    "# print(output_text)\n",
    "conversation = [ {'role': 'user', 'content': 'Hello?'} ] \n",
    "prompt = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "input_ids = tokenizer([prompt]).input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test = torch.tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14])\n",
    "test[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").cuda()\n",
    "\n",
    "start = time.time()\n",
    "output_ids = model.generate(input_ids,\n",
    "                            max_new_tokens=512,\n",
    "                            do_sample=True,\n",
    "                            temperature=0.9,\n",
    "                            top_p=0.9,\n",
    "                            top_k=0,\n",
    "                            use_cache=True,)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Hello Nice to meet you! give me a five story about human and AI collaboration\n",
      "\n",
      "Sure, here are five stories about human and AI collaboration:\n",
      "\n",
      "1. The AI-Powered Doctor's Assistant:\n",
      "\n",
      "In a small town, there was a doctor who was struggling to keep up with the demand for medical care. He was overworked and his patients were suffering as a result. One day, he met an AI developer who had created an AI-powered doctor's assistant. The AI was able to analyze medical data and provide accurate diagnoses and treatment recommendations. The doctor was skeptical at first, but he decided to give the AI a try.\n",
      "\n",
      "The AI quickly proved to be a valuable asset, freeing up the doctor's time to focus on more complex cases. The AI was able to identify patterns and anomalies in patient data that the doctor had missed, and it even helped the doctor to identify a rare disease that he had never seen before. The patients were impressed with the AI's accuracy and the doctor's improved bedside manner. The collaboration between the doctor and the AI improved the quality of care for the patients and reduced the doctor's workload.\n",
      "\n",
      "2. The AI-Powered Law Firm:\n",
      "\n",
      "A law firm was struggling to keep up with the increasing volume of legal cases. The lawyers were working long hours, but they were still falling behind. One day, they decided to try using an AI-powered legal assistant. The AI was able to analyze legal precedents and provide recommendations for case strategy.\n",
      "\n",
      "The lawyers were skeptical at first, but they quickly realized that the AI was a valuable asset. The AI was able to identify weaknesses in their cases that they had missed, and it even helped them to identify new legal precedents that they could use to strengthen their arguments. The clients were impressed with the law firm's improved efficiency and accuracy, and the lawyers were able to take on more cases without sacrificing quality. The collaboration between the lawyers and the AI improved the firm's reputation and profitability.\n",
      "\n",
      "3. The AI-Powered Factory:\n",
      "\n",
      "A manufacturing company was struggling to keep up with demand for their products. The factory was running 24/7, but they were still falling behind. One day, they decided to try using an AI-powered factory manager\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.decode(output_ids[0])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10810041194781661\n"
     ]
    }
   ],
   "source": [
    "print((end-start)/(len(output_ids[0])-len(input_ids[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jewon/code/FASTLLM/EAGLE/test.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m prompt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHello Nice to meet you! give me a five story about human and AI\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m input_ids\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtokenizer([prompt])\u001b[39m.\u001b[39minput_ids\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "prompt=\"Hello Nice to meet you! give me a five story about human and AI\"\n",
    "input_ids=model.tokenizer([prompt]).input_ids\n",
    "input_ids = torch.as_tensor(input_ids).cuda()\n",
    "start = time.time()\n",
    "\n",
    "output_ids=model.eagenerate(input_ids,\n",
    "                            temperature=0.9,\n",
    "                            max_new_tokens=512)\n",
    "end = time.time()\n",
    "\n",
    "output=model.tokenizer.decode(output_ids[0])\n",
    "\n",
    "print(((end-start)/(len(output_ids[0])- len(input_ids[0])))*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [1, 1, 26, 26] at index 2 does not match the shape of the indexed tensor [1, 1, 17, 17] at index 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jewon/code/FASTLLM/EAGLE/test.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m start_base \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mbase_model\u001b[39m.\u001b[39;49mgenerate(input_ids,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                      temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                      max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m end_base \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/transformers/generation/utils.py:1602\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1586\u001b[0m         input_ids,\n\u001b[1;32m   1587\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1599\u001b[0m     )\n\u001b[1;32m   1600\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1601\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1603\u001b[0m         input_ids,\n\u001b[1;32m   1604\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1605\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1606\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1607\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1608\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1609\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1610\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1611\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1612\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1616\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/transformers/generation/utils.py:2450\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2447\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2449\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2450\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2451\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2452\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2453\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2454\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2455\u001b[0m )\n\u001b[1;32m   2457\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2458\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/root/anaconda3/envs/EAGLE/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/code/FASTLLM/EAGLE/model/modeling_llama_kv.py:1170\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1165\u001b[0m return_dict \u001b[39m=\u001b[39m (\n\u001b[1;32m   1166\u001b[0m     return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1167\u001b[0m )\n\u001b[1;32m   1169\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1171\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1172\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1173\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1174\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1175\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1176\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1177\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1178\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1179\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1180\u001b[0m )\n\u001b[1;32m   1182\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretraining_tp \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/FASTLLM/EAGLE/model/modeling_llama_kv.py:995\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\n\u001b[1;32m    991\u001b[0m         (batch_size, seq_length_with_past),\n\u001b[1;32m    992\u001b[0m         dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool,\n\u001b[1;32m    993\u001b[0m         device\u001b[39m=\u001b[39minputs_embeds\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 995\u001b[0m attention_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_decoder_attention_mask(\n\u001b[1;32m    996\u001b[0m     attention_mask,\n\u001b[1;32m    997\u001b[0m     (batch_size, seq_length),\n\u001b[1;32m    998\u001b[0m     inputs_embeds,\n\u001b[1;32m    999\u001b[0m     past_key_values_length,\n\u001b[1;32m   1000\u001b[0m )\n\u001b[1;32m   1002\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds\n\u001b[1;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/code/FASTLLM/EAGLE/model/modeling_llama_kv.py:918\u001b[0m, in \u001b[0;36mLlamaModel._prepare_decoder_attention_mask\u001b[0;34m(self, attention_mask, input_shape, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    916\u001b[0m     tree_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_mask\n\u001b[1;32m    917\u001b[0m     tree_len \u001b[39m=\u001b[39m tree_mask\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 918\u001b[0m     combined_attention_mask[:, :, \u001b[39m-\u001b[39;49mtree_len:, \u001b[39m-\u001b[39;49mtree_len:][\n\u001b[1;32m    919\u001b[0m         tree_mask \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m\n\u001b[1;32m    920\u001b[0m         ] \u001b[39m=\u001b[39m combined_attention_mask\u001b[39m.\u001b[39mmin()\n\u001b[1;32m    922\u001b[0m \u001b[39mreturn\u001b[39;00m combined_attention_mask\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [1, 1, 26, 26] at index 2 does not match the shape of the indexed tensor [1, 1, 17, 17] at index 2"
     ]
    }
   ],
   "source": [
    "start_base = time.time()\n",
    "model.base_model.generate(input_ids,\n",
    "                     temperature=0.5,\n",
    "                     max_new_tokens=512)\n",
    "end_base = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jewon/code/FASTLLM/EAGLE/test.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.163.208/home/jewon/code/FASTLLM/EAGLE/test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(((end\u001b[39m-\u001b[39mstart)\u001b[39m/\u001b[39m(\u001b[39mlen\u001b[39m(output_ids[\u001b[39m0\u001b[39m])\u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(input_ids[\u001b[39m0\u001b[39m])))\u001b[39m*\u001b[39m\u001b[39m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "print(((end-start)/(len(output_ids[0])- len(input_ids[0])))*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tmp = torch.randn(2,3,4)\n",
    "another = torch.randint(0, 3, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape, another.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2285, -0.2771, -1.2256,  0.2589],\n",
       "         [ 0.7169, -0.4452,  0.0709, -0.7919],\n",
       "         [ 1.3631, -2.1339, -0.1270,  0.6295]],\n",
       "\n",
       "        [[-0.2772,  1.5934,  0.0378,  0.5314],\n",
       "         [ 0.5136, -1.2431, -1.5626,  0.5618],\n",
       "         [ 0.3346, -0.6924, -1.3657,  2.2490]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2285, -0.2771, -1.2256,  0.2589],\n",
       "         [-1.2285, -0.2771, -1.2256,  0.2589]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0, another]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAGLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
